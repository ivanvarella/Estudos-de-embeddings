# ğŸ§  Embeddings AvanÃ§ados e Clustering SemÃ¢ntico

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://python.org)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org)
[![Elasticsearch](https://img.shields.io/badge/Elasticsearch-8.11.0-yellow.svg)](https://elastic.co)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Projeto educacional completo** para estudo de embeddings de texto e algoritmos de clustering semÃ¢ntico, com sistema de cache inteligente usando Elasticsearch.

## ğŸ“‹ Ãndice

- [ğŸ¯ VisÃ£o Geral](#-visÃ£o-geral)
- [âœ¨ Funcionalidades](#-funcionalidades)
- [ğŸ› ï¸ Tecnologias Utilizadas](#ï¸-tecnologias-utilizadas)
- [ğŸ“¦ InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [ğŸš€ ExecuÃ§Ã£o](#-execuÃ§Ã£o)
- [ğŸ“Š Estrutura do Projeto](#-estrutura-do-projeto)
- [ğŸ“š DocumentaÃ§Ã£o](#-documentaÃ§Ã£o)
- [ğŸ”§ ConfiguraÃ§Ã£o](#-configuraÃ§Ã£o)
- [ğŸ’¡ Exemplos de Uso](#-exemplos-de-uso)
- [ğŸ¤ ContribuiÃ§Ã£o](#-contribuiÃ§Ã£o)
- [ğŸ“„ LicenÃ§a](#-licenÃ§a)

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um **sistema completo de anÃ¡lise de embeddings de texto** e clustering semÃ¢ntico, desenvolvido como material educacional para a disciplina de **InteligÃªncia Computacional para Engenharia de ProduÃ§Ã£o**.

O sistema combina **5 tipos diferentes de embeddings** (TF-IDF, Word2Vec, BERT, Sentence-BERT, OpenAI) com **3 algoritmos de clustering** (K-Means, DBSCAN, HDBSCAN) para anÃ¡lise semÃ¢ntica de textos, utilizando o dataset **20 Newsgroups** como base de dados.

### ğŸ“ Objetivos Educacionais

- **Compreender** a evoluÃ§Ã£o dos embeddings de texto (clÃ¡ssicos â†’ modernos)
- **Implementar** diferentes tÃ©cnicas de representaÃ§Ã£o semÃ¢ntica
- **Aplicar** algoritmos de clustering em dados textuais
- **Visualizar** resultados em 2D/3D com tÃ©cnicas de reduÃ§Ã£o dimensional
- **Comparar** performance entre diferentes abordagens
- **Utilizar** sistemas de cache para otimizaÃ§Ã£o de performance

### ğŸ“š Notebooks Modulares

O projeto estÃ¡ organizado em **5 notebooks modulares** que devem ser executados em sequÃªncia:

1. **Part1: PreparaÃ§Ã£o e Dataset** - ConfiguraÃ§Ã£o e carregamento dos dados
2. **Part2: Embeddings Locais** - TF-IDF, Word2Vec, BERT, Sentence-BERT
3. **Part3: Embeddings OpenAI** - Embeddings de Ãºltima geraÃ§Ã£o
4. **Part4: AnÃ¡lise Comparativa** - ComparaÃ§Ã£o entre todos os embeddings
5. **Part5: Clustering e ML** - ReduÃ§Ã£o dimensional e clustering

## âœ¨ Funcionalidades

### ğŸ”¤ Embeddings Implementados

- **TF-IDF**: RepresentaÃ§Ã£o baseada em frequÃªncia de termos
- **Word2Vec**: Embeddings contextuais clÃ¡ssicos (Gensim)
- **BERT**: RepresentaÃ§Ãµes bidirecionais modernas
- **Sentence-BERT**: Otimizado para similaridade de sentenÃ§as
- **OpenAI**: Embeddings de Ãºltima geraÃ§Ã£o (GPT-3.5/4)

### ğŸ¯ Algoritmos de Clustering

- **K-Means**: Clustering particional clÃ¡ssico
- **DBSCAN**: Clustering baseado em densidade
- **HDBSCAN**: Hierarchical DBSCAN melhorado

### ğŸ“Š VisualizaÃ§Ãµes

- **PCA**: ReduÃ§Ã£o dimensional linear
- **t-SNE**: ReduÃ§Ã£o dimensional nÃ£o-linear
- **UMAP**: ReduÃ§Ã£o dimensional moderna e eficiente

### ğŸ” Sistema de Cache

- **Elasticsearch**: Cache inteligente de embeddings
- **VerificaÃ§Ã£o de duplicatas**: Evita reprocessamento
- **ValidaÃ§Ã£o de integridade**: Garante consistÃªncia dos dados
- **Scroll API**: Suporte para grandes volumes de dados (>10k docs)

## ğŸ› ï¸ Tecnologias Utilizadas

### Core

- **Python 3.8+**
- **Jupyter Notebook**
- **NumPy & Pandas**
- **Scikit-learn**

### Embeddings

- **Sentence Transformers**
- **Gensim (Word2Vec)**
- **OpenAI API**
- **Transformers (BERT)**

### Clustering

- **HDBSCAN**
- **Scikit-learn (K-Means, DBSCAN)**

### VisualizaÃ§Ã£o

- **Matplotlib & Seaborn**
- **Plotly**
- **UMAP**

### Cache & Storage

- **Elasticsearch 8.11.0**
- **Kibana**

## ğŸ“¦ InstalaÃ§Ã£o

### **PrÃ©-requisitos**

- Python 3.8 ou superior
- Docker Desktop (para Elasticsearch)
- Git

### **1. Clone o RepositÃ³rio**

```bash
git clone https://github.com/ivanvarella/Estudos-de-embeddings.git
cd Embeddings_5.1
```

### **2. InstalaÃ§Ã£o do Docker Desktop**

#### Windows

1. Baixe o [Docker Desktop para Windows](https://www.docker.com/products/docker-desktop/)
2. Execute o instalador e siga as instruÃ§Ãµes
3. Reinicie o computador se necessÃ¡rio

#### macOS

1. Baixe o [Docker Desktop para Mac](https://www.docker.com/products/docker-desktop/)
2. Arraste o aplicativo para a pasta Applications
3. Execute o Docker Desktop

#### Linux (Ubuntu/Debian)

```bash
# Atualizar pacotes
sudo apt update

# Instalar dependÃªncias
sudo apt install apt-transport-https ca-certificates curl gnupg lsb-release

# Adicionar chave GPG oficial do Docker
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# Adicionar repositÃ³rio Docker
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Instalar Docker
sudo apt update
sudo apt install docker-ce docker-ce-cli containerd.io

# Adicionar usuÃ¡rio ao grupo docker
sudo usermod -aG docker $USER
```

### **3. ConfiguraÃ§Ã£o do Ambiente Python**

```bash
# Criar ambiente virtual
python -m venv venv

# Ativar ambiente virtual
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Atualizar pip
pip install --upgrade pip

# Instalar dependÃªncias
pip install -r requirements.txt

# Verificar instalaÃ§Ã£o
python -c "import numpy, pandas, sklearn; print('âœ… DependÃªncias instaladas!')"
```

### **4. ConfiguraÃ§Ã£o do Ambiente**

```bash
# Copiar arquivo de configuraÃ§Ã£o
cp src/setup/config_example.env src/setup/.env

# Editar configuraÃ§Ãµes (opcional)
# Windows: notepad src/setup/.env
# macOS/Linux: nano src/setup/.env
```

### **5. InicializaÃ§Ã£o do Elasticsearch**

#### Windows/Linux

```bash
# Iniciar serviÃ§os Docker
docker-compose -f docker-compose-win.yml up -d

# Verificar status
docker-compose -f docker-compose-win.yml ps

# Verificar Elasticsearch
curl http://localhost:9200
```

#### macOS

```bash
# Iniciar serviÃ§os Docker
docker-compose up -d

# Verificar status
docker-compose ps

# Verificar Elasticsearch
curl http://localhost:9200
```

### **6. ConfiguraÃ§Ã£o da API OpenAI (Opcional)**

Para usar embeddings da OpenAI, configure sua chave API:

```bash
# Editar arquivo .env
echo "OPENAI_API_KEY=sk-sua-chave-aqui" >> src/setup/.env
```

## ğŸš€ ExecuÃ§Ã£o

### **MÃ©todo 1: Jupyter Notebook (Recomendado)**

```bash
# Ativar ambiente virtual
# Windows: venv\Scripts\activate
# macOS/Linux: source venv/bin/activate

# Iniciar Jupyter
jupyter notebook src/

# Executar notebooks em sequÃªncia:
# 1. SeÃ§Ã£o5.1_Part1_Preparacao_Dataset.ipynb
# 2. SeÃ§Ã£o5.1_Part2_Embeddings_Locais.ipynb
# 3. SeÃ§Ã£o5.1_Part3_Embeddings_OpenAI.ipynb
# 4. SeÃ§Ã£o5.1_Part4_Analise_Comparativa.ipynb
# 5. SeÃ§Ã£o5.1_Part5_Clustering_ML.ipynb
```

### **MÃ©todo 2: Makefile (Automatizado)**

```bash
# Ver comandos disponÃ­veis
make help

# Instalar dependÃªncias
make install

# Testar ambiente
make test

# Iniciar Elasticsearch
make docker-up

# Iniciar Jupyter
make start

# Verificar status
make status
```

### **MÃ©todo 3: Scripts Individuais**

```bash
# Configurar ambiente
python src/setup/setup_environment.py

# Testar funcionalidades
python src/setup/test_environment.py

# Iniciar Jupyter
python src/setup/start_notebook.py
```

## ğŸ“Š Estrutura do Projeto

```
Embeddings_5.1/
â”œâ”€â”€ ğŸ“ src/                           # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ ğŸ““ SeÃ§Ã£o5.1_Part1_Preparacao_Dataset.ipynb
â”‚   â”œâ”€â”€ ğŸ““ SeÃ§Ã£o5.1_Part2_Embeddings_Locais.ipynb
â”‚   â”œâ”€â”€ ğŸ““ SeÃ§Ã£o5.1_Part3_Embeddings_OpenAI.ipynb
â”‚   â”œâ”€â”€ ğŸ““ SeÃ§Ã£o5.1_Part4_Analise_Comparativa.ipynb
â”‚   â”œâ”€â”€ ğŸ““ SeÃ§Ã£o5.1_Part5_Clustering_ML.ipynb
â”‚   â”œâ”€â”€ ğŸ”§ elasticsearch_manager.py   # Gerenciador de cache
â”‚   â”œâ”€â”€ ğŸ”§ elasticsearch_helpers.py   # FunÃ§Ãµes auxiliares
â”‚   â””â”€â”€ ğŸ“ setup/                     # Scripts de configuraÃ§Ã£o
â”‚       â”œâ”€â”€ âš™ï¸  config_example.env    # ConfiguraÃ§Ãµes de exemplo
â”‚       â”œâ”€â”€ ğŸ”§ setup_environment.py   # ConfiguraÃ§Ã£o do ambiente
â”‚       â”œâ”€â”€ ğŸ§ª test_environment.py    # Testes de funcionalidades
â”‚       â”œâ”€â”€ ğŸš€ start_notebook.py      # InicializaÃ§Ã£o do Jupyter
â”‚       â”œâ”€â”€ ğŸ“„ generate_pdf.py        # GeraÃ§Ã£o de PDFs
â”‚       â””â”€â”€ ğŸ§ª test_elasticsearch_cache.py
â”œâ”€â”€ ğŸ³ docker-compose.yml             # ServiÃ§os Docker (macOS)
â”œâ”€â”€ ğŸ³ docker-compose-win.yml         # ServiÃ§os Docker (Windows/Linux)
â”œâ”€â”€ âš™ï¸  Makefile                      # AutomaÃ§Ã£o de comandos
â”œâ”€â”€ ğŸ“‹ requirements.txt               # DependÃªncias Python
â”œâ”€â”€ ğŸ“ DocumentaÃ§Ã£o/                  # DocumentaÃ§Ã£o completa
â”‚   â””â”€â”€ ğŸ“„ DocumentaÃ§Ã£o.md
â”œâ”€â”€ ğŸ“ database/                      # Dados do Elasticsearch
â””â”€â”€ ğŸ“„ README.md                      # Este arquivo
```

## ğŸ“š DocumentaÃ§Ã£o

### **DocumentaÃ§Ã£o Completa**

- **Arquivo**: `DocumentaÃ§Ã£o/DocumentaÃ§Ã£o.md`
- **ConteÃºdo**: Guia completo de uso e configuraÃ§Ã£o
- **Acesso**: `make docs` ou abrir diretamente

### **Comandos de Acesso**

```bash
make docs          # Visualiza documentaÃ§Ã£o no terminal
make help          # Lista todos os comandos
make info          # InformaÃ§Ãµes do projeto
```

## ğŸ”§ ConfiguraÃ§Ã£o

### **VariÃ¡veis de Ambiente**

O projeto usa um arquivo `.env` para configuraÃ§Ãµes. Copie `src/setup/config_example.env` para `src/setup/.env` e configure:

```env
# OpenAI API (opcional)
OPENAI_API_KEY=sk-sua-chave-aqui

# Elasticsearch
ELASTICSEARCH_HOST=localhost
ELASTICSEARCH_PORT=9200

# ConfiguraÃ§Ãµes do dataset
DATASET_SIZE=20000
TEXT_MIN_LENGTH=20

# ConfiguraÃ§Ãµes de clustering
MAX_CLUSTERS=20
CLUSTERING_RANDOM_STATE=42
```

### **ConfiguraÃ§Ãµes AvanÃ§adas**

- **Processamento de textos**: `MAX_CHARS_PER_REQUEST`
- **Batch sizes**: `BATCH_SIZE_SMALL_TEXTS`, `BATCH_SIZE_MEDIUM_TEXTS`
- **VisualizaÃ§Ã£o**: `PLOT_WIDTH`, `PLOT_HEIGHT`
- **Cache**: `USE_ELASTICSEARCH_CACHE`, `FORCE_REGENERATE_EMBEDDINGS`

## ğŸ’¡ Exemplos de Uso

### **ExecuÃ§Ã£o BÃ¡sica**

```bash
# 1. Configurar ambiente
make install
make docker-up

# 2. Executar notebooks
make start

# 3. No Jupyter, executar em ordem:
#    Part1 â†’ Part2 â†’ Part3 â†’ Part4 â†’ Part5
```

### **ExecuÃ§Ã£o com OpenAI**

```bash
# 1. Configurar chave OpenAI
echo "OPENAI_API_KEY=sk-sua-chave-aqui" >> src/setup/.env

# 2. Executar normalmente
make start
```

### **GeraÃ§Ã£o de PDFs**

```bash
# Gerar PDFs de todos os notebooks
python src/setup/generate_pdf.py --notebook src/

# Gerar PDF de notebook especÃ­fico
python src/setup/generate_pdf.py --notebook src/SeÃ§Ã£o5.1_Part1_Preparacao_Dataset.ipynb
```

### **Limpeza e Reset**

```bash
# Limpar cache do Elasticsearch
make clean-all

# Parar serviÃ§os
make docker-down

# Limpar arquivos temporÃ¡rios
make clean
```

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

**ğŸ“ Aproveite a aula!** Este projeto oferece uma experiÃªncia completa de embeddings e clustering modernos.

**ğŸ“§ Contato**: Para dÃºvidas ou sugestÃµes, abra uma issue no repositÃ³rio.

---

_Ãšltima atualizaÃ§Ã£o: 2025-01-27_
_VersÃ£o: 2.0 - Estrutura Modular_

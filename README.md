# ğŸ§  Embeddings AvanÃ§ados e Clustering SemÃ¢ntico

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://python.org)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org)
[![Elasticsearch](https://img.shields.io/badge/Elasticsearch-8.11.0-yellow.svg)](https://elastic.co)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Projeto educacional completo** para estudo de embeddings de texto e algoritmos de clustering semÃ¢ntico, com sistema de cache inteligente usando Elasticsearch.

## ğŸ“‹ Ãndice

- [ğŸ¯ VisÃ£o Geral](#-visÃ£o-geral)
- [âœ¨ Funcionalidades](#-funcionalidades)
- [ğŸ› ï¸ Tecnologias Utilizadas](#ï¸-tecnologias-utilizadas)
- [ğŸ“¦ InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [ğŸš€ ExecuÃ§Ã£o](#-execuÃ§Ã£o)
- [ğŸ“Š Estrutura do Projeto](#-estrutura-do-projeto)
- [ğŸ“š DocumentaÃ§Ã£o](#-documentaÃ§Ã£o)
- [ğŸ”§ ConfiguraÃ§Ã£o](#-configuraÃ§Ã£o)
- [ğŸ’¡ Exemplos de Uso](#-exemplos-de-uso)
- [ğŸ¤ ContribuiÃ§Ã£o](#-contribuiÃ§Ã£o)
- [ğŸ“„ LicenÃ§a](#-licenÃ§a)

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um **sistema completo de anÃ¡lise de embeddings de texto** e clustering semÃ¢ntico, desenvolvido como material educacional para a disciplina de **InteligÃªncia Computacional para Engenharia de ProduÃ§Ã£o**. 

O sistema combina **5 tipos diferentes de embeddings** (TF-IDF, Word2Vec, BERT, Sentence-BERT, OpenAI) com **3 algoritmos de clustering** (K-Means, DBSCAN, HDBSCAN) para anÃ¡lise semÃ¢ntica de textos, utilizando o dataset **20 Newsgroups** como base de dados.

### ğŸ“ Objetivos Educacionais

- **Compreender** a evoluÃ§Ã£o dos embeddings de texto (clÃ¡ssicos â†’ modernos)
- **Implementar** diferentes tÃ©cnicas de representaÃ§Ã£o semÃ¢ntica
- **Aplicar** algoritmos de clustering em dados textuais
- **Visualizar** resultados em 2D/3D com tÃ©cnicas de reduÃ§Ã£o dimensional
- **Comparar** performance entre diferentes abordagens
- **Utilizar** sistemas de cache para otimizaÃ§Ã£o de performance

## âœ¨ Funcionalidades

### ğŸ§® **GeraÃ§Ã£o de Embeddings**
- **TF-IDF**: MÃ©todo clÃ¡ssico baseado em frequÃªncia de termos
- **Word2Vec**: Embeddings contextuais com treinamento local
- **BERT**: RepresentaÃ§Ãµes bidirecionais profundas
- **Sentence-BERT**: Otimizado para similaridade de sentenÃ§as
- **OpenAI**: Embeddings de Ãºltima geraÃ§Ã£o via API

### ğŸ” **Algoritmos de Clustering**
- **K-Means**: Clustering clÃ¡ssico baseado em distÃ¢ncias
- **DBSCAN**: Clustering baseado em densidade
- **HDBSCAN**: Clustering hierÃ¡rquico robusto

### ğŸ“Š **VisualizaÃ§Ã£o e AnÃ¡lise**
- **ReduÃ§Ã£o Dimensional**: PCA, t-SNE, UMAP
- **VisualizaÃ§Ãµes Interativas**: Plotly com grÃ¡ficos 2D/3D
- **MÃ©tricas de AvaliaÃ§Ã£o**: Silhouette, ARI, NMI, Homogeneity
- **AnÃ¡lise Comparativa**: Benchmark entre diferentes mÃ©todos

### ğŸ—„ï¸ **Sistema de Cache Inteligente**
- **Elasticsearch**: Armazenamento persistente de embeddings
- **Cache AutomÃ¡tico**: Evita reprocessamento desnecessÃ¡rio
- **ValidaÃ§Ã£o de Integridade**: Hash MD5 para verificaÃ§Ã£o
- **Economia de Tempo**: 6x-12x mais rÃ¡pido em execuÃ§Ãµes subsequentes

### ğŸ“ˆ **AnÃ¡lise Detalhada**
- **EstatÃ­sticas Completas**: DimensÃµes, densidade, normalizaÃ§Ã£o
- **Exemplos PrÃ¡ticos**: VisualizaÃ§Ã£o de embeddings individuais
- **InterpretaÃ§Ã£o DidÃ¡tica**: ExplicaÃ§Ãµes detalhadas de cada conceito
- **RelatÃ³rios AutomÃ¡ticos**: SumÃ¡rios comparativos e mÃ©tricas

## ğŸ› ï¸ Tecnologias Utilizadas

### **Core Libraries**
- **Python 3.8+**: Linguagem principal
- **NumPy**: ComputaÃ§Ã£o numÃ©rica
- **Pandas**: ManipulaÃ§Ã£o de dados
- **Scikit-learn**: Machine learning e clustering

### **Embeddings & NLP**
- **Gensim**: Word2Vec e modelos de linguagem
- **Sentence-Transformers**: BERT e Sentence-BERT
- **OpenAI API**: Embeddings de Ãºltima geraÃ§Ã£o
- **Transformers**: Modelos BERT prÃ©-treinados

### **VisualizaÃ§Ã£o**
- **Matplotlib**: GrÃ¡ficos estÃ¡ticos
- **Seaborn**: VisualizaÃ§Ãµes estatÃ­sticas
- **Plotly**: GrÃ¡ficos interativos
- **UMAP**: ReduÃ§Ã£o dimensional nÃ£o-linear

### **Clustering AvanÃ§ado**
- **HDBSCAN**: Clustering hierÃ¡rquico baseado em densidade
- **DBSCAN**: Clustering baseado em densidade clÃ¡ssico

### **Infraestrutura**
- **Elasticsearch 8.11.0**: Sistema de cache e busca
- **Kibana**: Interface de visualizaÃ§Ã£o do Elasticsearch
- **Docker**: ContainerizaÃ§Ã£o dos serviÃ§os
- **Jupyter Notebook**: Ambiente interativo

### **UtilitÃ¡rios**
- **python-dotenv**: Gerenciamento de variÃ¡veis de ambiente
- **tqdm**: Barras de progresso
- **wordcloud**: Nuvens de palavras

## ğŸ“¦ InstalaÃ§Ã£o

### **PrÃ©-requisitos**

- **Python 3.8+** (recomendado: 3.10+)
- **Git** (para clonagem do repositÃ³rio)
- **Docker** e **Docker Compose** (para Elasticsearch)
- **8GB+ RAM** (recomendado para processamento completo)

### **1. Clonagem do RepositÃ³rio**

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/embeddings-avancados-clustering.git

# Entre no diretÃ³rio
cd embeddings-avancados-clustering
```

### **2. CriaÃ§Ã£o do Ambiente Virtual**

#### **Windows (PowerShell)**
```powershell
# Criar ambiente virtual
python -m venv .venv

# Ativar ambiente virtual
.venv\Scripts\Activate.ps1

# Se houver erro de polÃ­tica de execuÃ§Ã£o:
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

#### **macOS/Linux**
```bash
# Criar ambiente virtual
python3 -m venv .venv

# Ativar ambiente virtual
source .venv/bin/activate
```

### **3. InstalaÃ§Ã£o das DependÃªncias**

```bash
# Atualizar pip
pip install --upgrade pip

# Instalar dependÃªncias
pip install -r requirements.txt

# Verificar instalaÃ§Ã£o
python -c "import numpy, pandas, sklearn; print('âœ… DependÃªncias instaladas!')"
```

### **4. ConfiguraÃ§Ã£o do Ambiente**

```bash
# Copiar arquivo de configuraÃ§Ã£o
cp setup/config_example.env setup/.env

# Editar configuraÃ§Ãµes (opcional)
# Windows: notepad setup/.env
# macOS/Linux: nano setup/.env
```

### **5. InicializaÃ§Ã£o do Elasticsearch**

```bash
# Iniciar serviÃ§os Docker
docker-compose up -d

# Verificar status
docker-compose ps

# Verificar Elasticsearch
curl http://localhost:9200
```

### **6. ConfiguraÃ§Ã£o da API OpenAI (Opcional)**

Para usar embeddings da OpenAI, configure sua chave API:

```bash
# Editar arquivo .env
echo "OPENAI_API_KEY=sk-sua-chave-aqui" >> setup/.env
```

## ğŸš€ ExecuÃ§Ã£o

### **MÃ©todo 1: Jupyter Notebook (Recomendado)**

```bash
# Iniciar Jupyter
jupyter notebook

# Abrir o arquivo: SeÃ§Ã£o5.1_Embeddings.ipynb
# Executar cÃ©lulas sequencialmente
```

### **MÃ©todo 2: Makefile (Automatizado)**

```bash
# Ver comandos disponÃ­veis
make help

# Instalar dependÃªncias
make install

# Testar ambiente
make test

# Iniciar notebook
make start

# Iniciar Elasticsearch
make docker-up

# Verificar status
make status
```

### **MÃ©todo 3: ExecuÃ§Ã£o Direta**

```bash
# Executar notebook programaticamente
jupyter nbconvert --to notebook --execute SeÃ§Ã£o5.1_Embeddings.ipynb
```

## ğŸ“Š Estrutura do Projeto

```
Embeddings_5.1/
â”œâ”€â”€ ğŸ“„ README.md                          # Este arquivo
â”œâ”€â”€ ğŸ“„ requirements.txt                   # DependÃªncias Python
â”œâ”€â”€ ğŸ“„ docker-compose.yml                 # ConfiguraÃ§Ã£o Docker
â”œâ”€â”€ ğŸ“„ Makefile                          # AutomaÃ§Ã£o de tarefas
â”œâ”€â”€ ğŸ““ SeÃ§Ã£o5.1_Embeddings.ipynb         # Notebook principal
â”œâ”€â”€ ğŸ elasticsearch_manager.py           # Gerenciador de cache
â”œâ”€â”€ ğŸ“ setup/                            # ConfiguraÃ§Ãµes e utilitÃ¡rios
â”‚   â”œâ”€â”€ config_example.env               # Exemplo de configuraÃ§Ã£o
â”‚   â”œâ”€â”€ setup_environment.py             # Script de setup
â”‚   â”œâ”€â”€ test_environment.py              # Testes do ambiente
â”‚   â”œâ”€â”€ test_elasticsearch_cache.py      # Testes do cache
â”‚   â””â”€â”€ start_notebook.py                # Inicializador do notebook
â”œâ”€â”€ ğŸ“ DocumentaÃ§Ã£o/                     # DocumentaÃ§Ã£o detalhada
â”‚   â””â”€â”€ DocumentaÃ§Ã£o.md                  # Manual completo
â””â”€â”€ ğŸ“ .venv/                           # Ambiente virtual (criado automaticamente)
```

## ğŸ“š DocumentaÃ§Ã£o

### **DocumentaÃ§Ã£o Completa**
- **[DocumentaÃ§Ã£o.md](DocumentaÃ§Ã£o/DocumentaÃ§Ã£o.md)**: Manual detalhado com conceitos teÃ³ricos, exemplos prÃ¡ticos e troubleshooting

### **Conceitos Principais**

#### **Embeddings de Texto**
- **TF-IDF**: FrequÃªncia de termos Ã— FrequÃªncia inversa de documentos
- **Word2Vec**: RepresentaÃ§Ãµes contextuais baseadas em janela deslizante
- **BERT**: Transformers bidirecionais com attention mechanism
- **Sentence-BERT**: OtimizaÃ§Ã£o para similaridade de sentenÃ§as
- **OpenAI**: Embeddings de Ãºltima geraÃ§Ã£o treinados para similaridade

#### **Algoritmos de Clustering**
- **K-Means**: Particionamento em k clusters esfÃ©ricos
- **DBSCAN**: Clustering baseado em densidade com detecÃ§Ã£o de outliers
- **HDBSCAN**: Clustering hierÃ¡rquico robusto com clusters de tamanhos variados

#### **TÃ©cnicas de VisualizaÃ§Ã£o**
- **PCA**: ReduÃ§Ã£o linear preservando variÃ¢ncia global
- **t-SNE**: ReduÃ§Ã£o nÃ£o-linear preservando distÃ¢ncias locais
- **UMAP**: Balanceamento entre estrutura local e global

## ğŸ”§ ConfiguraÃ§Ã£o

### **VariÃ¡veis de Ambiente**

Crie o arquivo `setup/.env` baseado em `setup/config_example.env`:

```env
# Elasticsearch
ELASTICSEARCH_HOST=localhost
ELASTICSEARCH_PORT=9200
USE_ELASTICSEARCH_CACHE=true
FORCE_REGENERATE_EMBEDDINGS=false

# OpenAI (opcional)
OPENAI_API_KEY=sk-sua-chave-aqui

# ConfiguraÃ§Ãµes de Processamento
MAX_CHARS_PER_REQUEST=30000
BATCH_SIZE_SMALL_TEXTS=8
BATCH_SIZE_MEDIUM_TEXTS=4
BATCH_SIZE_LARGE_TEXTS=2
TEXT_MIN_LENGTH=50

# ConfiguraÃ§Ãµes de Clustering
MAX_CLUSTERS=20
CLUSTERING_RANDOM_STATE=42

# ConfiguraÃ§Ãµes de VisualizaÃ§Ã£o
PLOT_WIDTH=800
PLOT_HEIGHT=600
LOG_LEVEL=INFO
```

### **ConfiguraÃ§Ã£o do Elasticsearch**

O Elasticsearch Ã© configurado automaticamente via Docker Compose:

- **Porta**: 9200 (Elasticsearch), 5601 (Kibana)
- **MemÃ³ria**: 1GB (configurÃ¡vel)
- **SeguranÃ§a**: Desabilitada para ambiente educacional
- **Dados**: Persistidos em volume Docker

### **ConfiguraÃ§Ã£o da OpenAI**

1. Obtenha uma chave API em [platform.openai.com](https://platform.openai.com)
2. Adicione a chave no arquivo `setup/.env`
3. Configure limites de uso conforme necessÃ¡rio

## ğŸ’¡ Exemplos de Uso

### **1. AnÃ¡lise BÃ¡sica de Embeddings**

```python
# Carregar dados
from sklearn.datasets import fetch_20newsgroups
newsgroups = fetch_20newsgroups(subset='train', categories=['sci.med', 'sci.crypt'])

# Gerar embeddings TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(max_features=1000)
embeddings = vectorizer.fit_transform(newsgroups.data)

# Aplicar clustering
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=2, random_state=42)
clusters = kmeans.fit_predict(embeddings.toarray())
```

### **2. Uso do Sistema de Cache**

```python
# Verificar cache
from elasticsearch_manager import check_embeddings_in_cache
exists, existing, missing = check_embeddings_in_cache('embeddings_tfidf', doc_ids)

# Carregar do cache
if exists:
    embeddings = load_embeddings_from_cache('embeddings_tfidf', doc_ids)
else:
    # Gerar novos embeddings
    embeddings = generate_embeddings(texts)
    save_embeddings_to_cache('embeddings_tfidf', embeddings, doc_ids, texts, 'tfidf')
```

### **3. VisualizaÃ§Ã£o de Resultados**

```python
# Reduzir dimensÃµes
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
embeddings_2d = pca.fit_transform(embeddings)

# Visualizar com Plotly
import plotly.express as px
fig = px.scatter(x=embeddings_2d[:, 0], y=embeddings_2d[:, 1], 
                 color=clusters, title='Clustering Results')
fig.show()
```

## ğŸ“ Casos de Uso Educacionais

### **1. ComparaÃ§Ã£o de Embeddings**
- Execute o notebook completo
- Compare visualizaÃ§Ãµes de diferentes tipos de embeddings
- Analise mÃ©tricas de qualidade

### **2. AnÃ¡lise de Clustering**
- Teste diferentes algoritmos de clustering
- Compare mÃ©tricas de avaliaÃ§Ã£o
- Identifique o melhor mÃ©todo para seus dados

### **3. OtimizaÃ§Ã£o de Performance**
- Use o sistema de cache para evitar reprocessamento
- Compare tempos de execuÃ§Ã£o com/sem cache
- Analise economia de recursos

### **4. ExperimentaÃ§Ã£o**
- Modifique parÃ¢metros dos algoritmos
- Teste com diferentes datasets
- Implemente novas mÃ©tricas de avaliaÃ§Ã£o

## ğŸ” Troubleshooting

### **Problemas Comuns**

#### **Erro de MemÃ³ria**
```bash
# Aumentar limite de memÃ³ria do Jupyter
jupyter notebook --NotebookApp.max_buffer_size=1000000000
```

#### **Elasticsearch nÃ£o conecta**
```bash
# Verificar status do Docker
docker-compose ps

# Reiniciar serviÃ§os
docker-compose restart

# Verificar logs
docker-compose logs elasticsearch
```

#### **DependÃªncias nÃ£o instalam**
```bash
# Atualizar pip
pip install --upgrade pip setuptools wheel

# Instalar com verbose
pip install -r requirements.txt -v
```

#### **OpenAI API falha**
- Verificar chave API no arquivo `.env`
- Verificar limites de uso na conta OpenAI
- Verificar conectividade com internet

### **Logs e Debug**

```bash
# Ver logs do Elasticsearch
docker-compose logs -f elasticsearch

# Testar ambiente
python setup/test_environment.py

# Testar cache
python setup/test_elasticsearch_cache.py
```

## ğŸ¤ ContribuiÃ§Ã£o

### **Como Contribuir**

1. **Fork** o repositÃ³rio
2. **Crie** uma branch para sua feature (`git checkout -b feature/nova-funcionalidade`)
3. **Commit** suas mudanÃ§as (`git commit -am 'Adiciona nova funcionalidade'`)
4. **Push** para a branch (`git push origin feature/nova-funcionalidade`)
5. **Abra** um Pull Request

### **Ãreas de ContribuiÃ§Ã£o**

- **Novos tipos de embeddings**: Adicionar outros modelos
- **Algoritmos de clustering**: Implementar novos mÃ©todos
- **VisualizaÃ§Ãµes**: Melhorar grÃ¡ficos e interatividade
- **DocumentaÃ§Ã£o**: Expandir explicaÃ§Ãµes e exemplos
- **Testes**: Adicionar testes automatizados
- **Performance**: Otimizar cÃ³digo e cache

### **PadrÃµes de CÃ³digo**

- **PEP 8**: Seguir convenÃ§Ãµes do Python
- **Docstrings**: Documentar todas as funÃ§Ãµes
- **Type Hints**: Usar anotaÃ§Ãµes de tipo
- **Testes**: Escrever testes para novas funcionalidades

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a **LicenÃ§a MIT** - veja o arquivo [LICENSE](LICENSE) para detalhes.

### **Uso Educacional**

Este projeto foi desenvolvido especificamente para fins educacionais e pode ser usado livremente em:
- Cursos universitÃ¡rios
- Workshops e treinamentos
- Pesquisa acadÃªmica
- Projetos pessoais de aprendizado

### **AtribuiÃ§Ã£o**

Se usar este projeto em suas aulas ou pesquisas, por favor cite:

```
Embeddings AvanÃ§ados e Clustering SemÃ¢ntico
Disciplina: InteligÃªncia Computacional para Engenharia de ProduÃ§Ã£o
Universidade: [Sua Universidade]
Ano: 2025
```

## ğŸ“ Suporte

### **Canais de Suporte**

- **Issues**: [GitHub Issues](https://github.com/seu-usuario/embeddings-avancados-clustering/issues)
- **DiscussÃµes**: [GitHub Discussions](https://github.com/seu-usuario/embeddings-avancados-clustering/discussions)
- **Email**: [seu-email@universidade.edu](mailto:seu-email@universidade.edu)

### **Recursos Adicionais**

- **DocumentaÃ§Ã£o Oficial**: [DocumentaÃ§Ã£o.md](DocumentaÃ§Ã£o/DocumentaÃ§Ã£o.md)
- **Exemplos**: Veja a pasta `examples/` (em desenvolvimento)
- **VÃ­deos Tutoriais**: [Canal YouTube](https://youtube.com/playlist) (em desenvolvimento)

---

<div align="center">

**ğŸ“ Desenvolvido para fins educacionais**  
**ğŸ“š InteligÃªncia Computacional para Engenharia de ProduÃ§Ã£o**  
**ğŸš€ 2025**

[![GitHub](https://img.shields.io/badge/GitHub-Repository-black?logo=github)](https://github.com/seu-usuario/embeddings-avancados-clustering)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange?logo=jupyter)](https://jupyter.org)
[![Python](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python)](https://python.org)

</div>

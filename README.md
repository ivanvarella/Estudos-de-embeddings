# üß† Embeddings Avan√ßados e Clustering Sem√¢ntico

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://python.org)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org)
[![Elasticsearch](https://img.shields.io/badge/Elasticsearch-8.11.0-yellow.svg)](https://elastic.co)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Projeto educacional completo** para estudo de embeddings de texto e algoritmos de clustering sem√¢ntico, com sistema de cache inteligente usando Elasticsearch.

## üìã √çndice

- [üéØ Vis√£o Geral](#-vis√£o-geral)
- [‚ú® Funcionalidades](#-funcionalidades)
- [üõ†Ô∏è Tecnologias Utilizadas](#Ô∏è-tecnologias-utilizadas)
- [üì¶ Instala√ß√£o](#-instala√ß√£o)
- [üöÄ Execu√ß√£o](#-execu√ß√£o)
- [üìä Estrutura do Projeto](#-estrutura-do-projeto)
- [üìö Documenta√ß√£o](#-documenta√ß√£o)
- [üîß Configura√ß√£o](#-configura√ß√£o)
- [üí° Exemplos de Uso](#-exemplos-de-uso)
- [ü§ù Contribui√ß√£o](#-contribui√ß√£o)
- [üìÑ Licen√ßa](#-licen√ßa)

## üéØ Vis√£o Geral

Este projeto implementa um **sistema completo de an√°lise de embeddings de texto** e clustering sem√¢ntico, desenvolvido como material educacional para a disciplina de **Intelig√™ncia Computacional para Engenharia de Produ√ß√£o**.

O sistema combina **5 tipos diferentes de embeddings** (TF-IDF, Word2Vec, BERT, Sentence-BERT, OpenAI) com **3 algoritmos de clustering** (K-Means, DBSCAN, HDBSCAN) para an√°lise sem√¢ntica de textos, utilizando o dataset **20 Newsgroups** como base de dados.

### üéì Objetivos Educacionais

- **Compreender** a evolu√ß√£o dos embeddings de texto (cl√°ssicos ‚Üí modernos)
- **Implementar** diferentes t√©cnicas de representa√ß√£o sem√¢ntica
- **Aplicar** algoritmos de clustering em dados textuais
- **Visualizar** resultados em 2D/3D com t√©cnicas de redu√ß√£o dimensional
- **Comparar** performance entre diferentes abordagens
- **Utilizar** sistemas de cache para otimiza√ß√£o de performance

### üìö Notebooks Modulares

O projeto est√° organizado em **5 notebooks modulares** que devem ser executados em sequ√™ncia:

1. **Part1: Prepara√ß√£o e Dataset** - Configura√ß√£o e carregamento dos dados
2. **Part2: Embeddings Locais** - TF-IDF, Word2Vec, BERT, Sentence-BERT
3. **Part3: Embeddings OpenAI** - Embeddings de √∫ltima gera√ß√£o
4. **Part4: An√°lise Comparativa** - Compara√ß√£o entre todos os embeddings
5. **Part5: Clustering e ML** - Redu√ß√£o dimensional e clustering

## ‚ú® Funcionalidades

### üî§ Embeddings Implementados

- **TF-IDF**: Representa√ß√£o baseada em frequ√™ncia de termos
- **Word2Vec**: Embeddings contextuais cl√°ssicos (Gensim)
- **BERT**: Representa√ß√µes bidirecionais modernas
- **Sentence-BERT**: Otimizado para similaridade de senten√ßas
- **OpenAI**: Embeddings de √∫ltima gera√ß√£o (GPT-3.5/4)

### üéØ Algoritmos de Clustering

- **K-Means**: Clustering particional cl√°ssico
- **DBSCAN**: Clustering baseado em densidade
- **HDBSCAN**: Hierarchical DBSCAN melhorado

### üìä Visualiza√ß√µes

- **PCA**: Redu√ß√£o dimensional linear
- **t-SNE**: Redu√ß√£o dimensional n√£o-linear
- **UMAP**: Redu√ß√£o dimensional moderna e eficiente

### üîç Sistema de Cache

- **Elasticsearch**: Cache inteligente de embeddings
- **Verifica√ß√£o de duplicatas**: Evita reprocessamento
- **Valida√ß√£o de integridade**: Garante consist√™ncia dos dados
- **Scroll API**: Suporte para grandes volumes de dados (>10k docs)

## üõ†Ô∏è Tecnologias Utilizadas

### Core
- **Python 3.8+**
- **Jupyter Notebook**
- **NumPy & Pandas**
- **Scikit-learn**

### Embeddings
- **Sentence Transformers**
- **Gensim (Word2Vec)**
- **OpenAI API**
- **Transformers (BERT)**

### Clustering
- **HDBSCAN**
- **Scikit-learn (K-Means, DBSCAN)**

### Visualiza√ß√£o
- **Matplotlib & Seaborn**
- **Plotly**
- **UMAP**

### Cache & Storage
- **Elasticsearch 8.11.0**
- **Kibana**

## üì¶ Instala√ß√£o

### **Pr√©-requisitos**

- Python 3.8 ou superior
- Docker Desktop (para Elasticsearch)
- Git

### **1. Clone o Reposit√≥rio**

```bash
git clone <repository-url>
cd Embeddings_5.1
```

### **2. Instala√ß√£o do Docker Desktop**

#### Windows
1. Baixe o [Docker Desktop para Windows](https://www.docker.com/products/docker-desktop/)
2. Execute o instalador e siga as instru√ß√µes
3. Reinicie o computador se necess√°rio

#### macOS
1. Baixe o [Docker Desktop para Mac](https://www.docker.com/products/docker-desktop/)
2. Arraste o aplicativo para a pasta Applications
3. Execute o Docker Desktop

#### Linux (Ubuntu/Debian)
```bash
# Atualizar pacotes
sudo apt update

# Instalar depend√™ncias
sudo apt install apt-transport-https ca-certificates curl gnupg lsb-release

# Adicionar chave GPG oficial do Docker
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# Adicionar reposit√≥rio Docker
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Instalar Docker
sudo apt update
sudo apt install docker-ce docker-ce-cli containerd.io

# Adicionar usu√°rio ao grupo docker
sudo usermod -aG docker $USER
```

### **3. Configura√ß√£o do Ambiente Python**

```bash
# Criar ambiente virtual
python -m venv venv

# Ativar ambiente virtual
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Atualizar pip
pip install --upgrade pip

# Instalar depend√™ncias
pip install -r requirements.txt

# Verificar instala√ß√£o
python -c "import numpy, pandas, sklearn; print('‚úÖ Depend√™ncias instaladas!')"
```

### **4. Configura√ß√£o do Ambiente**

```bash
# Copiar arquivo de configura√ß√£o
cp src/setup/config_example.env src/setup/.env

# Editar configura√ß√µes (opcional)
# Windows: notepad src/setup/.env
# macOS/Linux: nano src/setup/.env
```

### **5. Inicializa√ß√£o do Elasticsearch**

#### Windows/Linux
```bash
# Iniciar servi√ßos Docker
docker-compose -f docker-compose-win.yml up -d

# Verificar status
docker-compose -f docker-compose-win.yml ps

# Verificar Elasticsearch
curl http://localhost:9200
```

#### macOS
```bash
# Iniciar servi√ßos Docker
docker-compose up -d

# Verificar status
docker-compose ps

# Verificar Elasticsearch
curl http://localhost:9200
```

### **6. Configura√ß√£o da API OpenAI (Opcional)**

Para usar embeddings da OpenAI, configure sua chave API:

```bash
# Editar arquivo .env
echo "OPENAI_API_KEY=sk-sua-chave-aqui" >> src/setup/.env
```

## üöÄ Execu√ß√£o

### **M√©todo 1: Jupyter Notebook (Recomendado)**

```bash
# Ativar ambiente virtual
# Windows: venv\Scripts\activate
# macOS/Linux: source venv/bin/activate

# Iniciar Jupyter
jupyter notebook src/

# Executar notebooks em sequ√™ncia:
# 1. Se√ß√£o5.1_Part1_Preparacao_Dataset.ipynb
# 2. Se√ß√£o5.1_Part2_Embeddings_Locais.ipynb
# 3. Se√ß√£o5.1_Part3_Embeddings_OpenAI.ipynb
# 4. Se√ß√£o5.1_Part4_Analise_Comparativa.ipynb
# 5. Se√ß√£o5.1_Part5_Clustering_ML.ipynb
```

### **M√©todo 2: Makefile (Automatizado)**

```bash
# Ver comandos dispon√≠veis
make help

# Instalar depend√™ncias
make install

# Testar ambiente
make test

# Iniciar Elasticsearch
make docker-up

# Iniciar Jupyter
make start

# Verificar status
make status
```

### **M√©todo 3: Scripts Individuais**

```bash
# Configurar ambiente
python src/setup/setup_environment.py

# Testar funcionalidades
python src/setup/test_environment.py

# Iniciar Jupyter
python src/setup/start_notebook.py
```

## üìä Estrutura do Projeto

```
Embeddings_5.1/
‚îú‚îÄ‚îÄ üìÅ src/                           # C√≥digo fonte principal
‚îÇ   ‚îú‚îÄ‚îÄ üìì Se√ß√£o5.1_Part1_Preparacao_Dataset.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ üìì Se√ß√£o5.1_Part2_Embeddings_Locais.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ üìì Se√ß√£o5.1_Part3_Embeddings_OpenAI.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ üìì Se√ß√£o5.1_Part4_Analise_Comparativa.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ üìì Se√ß√£o5.1_Part5_Clustering_ML.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ üîß elasticsearch_manager.py   # Gerenciador de cache
‚îÇ   ‚îú‚îÄ‚îÄ üîß elasticsearch_helpers.py   # Fun√ß√µes auxiliares
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ setup/                     # Scripts de configura√ß√£o
‚îÇ       ‚îú‚îÄ‚îÄ ‚öôÔ∏è  config_example.env    # Configura√ß√µes de exemplo
‚îÇ       ‚îú‚îÄ‚îÄ üîß setup_environment.py   # Configura√ß√£o do ambiente
‚îÇ       ‚îú‚îÄ‚îÄ üß™ test_environment.py    # Testes de funcionalidades
‚îÇ       ‚îú‚îÄ‚îÄ üöÄ start_notebook.py      # Inicializa√ß√£o do Jupyter
‚îÇ       ‚îú‚îÄ‚îÄ üìÑ generate_pdf.py        # Gera√ß√£o de PDFs
‚îÇ       ‚îî‚îÄ‚îÄ üß™ test_elasticsearch_cache.py
‚îú‚îÄ‚îÄ üê≥ docker-compose.yml             # Servi√ßos Docker (macOS)
‚îú‚îÄ‚îÄ üê≥ docker-compose-win.yml         # Servi√ßos Docker (Windows/Linux)
‚îú‚îÄ‚îÄ ‚öôÔ∏è  Makefile                      # Automa√ß√£o de comandos
‚îú‚îÄ‚îÄ üìã requirements.txt               # Depend√™ncias Python
‚îú‚îÄ‚îÄ üìÅ Documenta√ß√£o/                  # Documenta√ß√£o completa
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ Documenta√ß√£o.md
‚îú‚îÄ‚îÄ üìÅ database/                      # Dados do Elasticsearch
‚îî‚îÄ‚îÄ üìÑ README.md                      # Este arquivo
```

## üìö Documenta√ß√£o

### **Documenta√ß√£o Completa**
- **Arquivo**: `Documenta√ß√£o/Documenta√ß√£o.md`
- **Conte√∫do**: Guia completo de uso e configura√ß√£o
- **Acesso**: `make docs` ou abrir diretamente

### **Comandos de Acesso**
```bash
make docs          # Visualiza documenta√ß√£o no terminal
make help          # Lista todos os comandos
make info          # Informa√ß√µes do projeto
```

## üîß Configura√ß√£o

### **Vari√°veis de Ambiente**

O projeto usa um arquivo `.env` para configura√ß√µes. Copie `src/setup/config_example.env` para `src/setup/.env` e configure:

```env
# OpenAI API (opcional)
OPENAI_API_KEY=sk-sua-chave-aqui

# Elasticsearch
ELASTICSEARCH_HOST=localhost
ELASTICSEARCH_PORT=9200

# Configura√ß√µes do dataset
DATASET_SIZE=20000
TEXT_MIN_LENGTH=20

# Configura√ß√µes de clustering
MAX_CLUSTERS=20
CLUSTERING_RANDOM_STATE=42
```

### **Configura√ß√µes Avan√ßadas**

- **Processamento de textos**: `MAX_CHARS_PER_REQUEST`
- **Batch sizes**: `BATCH_SIZE_SMALL_TEXTS`, `BATCH_SIZE_MEDIUM_TEXTS`
- **Visualiza√ß√£o**: `PLOT_WIDTH`, `PLOT_HEIGHT`
- **Cache**: `USE_ELASTICSEARCH_CACHE`, `FORCE_REGENERATE_EMBEDDINGS`

## üí° Exemplos de Uso

### **Execu√ß√£o B√°sica**

```bash
# 1. Configurar ambiente
make install
make docker-up

# 2. Executar notebooks
make start

# 3. No Jupyter, executar em ordem:
#    Part1 ‚Üí Part2 ‚Üí Part3 ‚Üí Part4 ‚Üí Part5
```

### **Execu√ß√£o com OpenAI**

```bash
# 1. Configurar chave OpenAI
echo "OPENAI_API_KEY=sk-sua-chave-aqui" >> src/setup/.env

# 2. Executar normalmente
make start
```

### **Gera√ß√£o de PDFs**

```bash
# Gerar PDFs de todos os notebooks
python src/setup/generate_pdf.py --notebook src/

# Gerar PDF de notebook espec√≠fico
python src/setup/generate_pdf.py --notebook src/Se√ß√£o5.1_Part1_Preparacao_Dataset.ipynb
```

### **Limpeza e Reset**

```bash
# Limpar cache do Elasticsearch
make clean-all

# Parar servi√ßos
make docker-down

# Limpar arquivos tempor√°rios
make clean
```

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

**üéì Aproveite a aula!** Este projeto oferece uma experi√™ncia completa de embeddings e clustering modernos.

**üìß Contato**: Para d√∫vidas ou sugest√µes, abra uma issue no reposit√≥rio.

---

_√öltima atualiza√ß√£o: 2025-01-27_
_Vers√£o: 2.0 - Estrutura Modular_